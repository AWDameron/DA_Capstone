{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import convenient_methods as c_m\n",
    "import convenient_lists as c_l\n",
    "import linkedIn_scraper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Panda Methods ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Folders, and then Scrape Data\n",
    "\n",
    "Run if you want to check out the scraping process, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Scraper ##\n",
    "## Please only use characters that are acceptable to file names as an input. ##\n",
    "## Should just use a number in the search quantity as well ##\n",
    "c_m.create_folders()\n",
    "\n",
    "search_input = input(\"Put in what you are looking for?\")\n",
    "search_quantity = int(input(\"At least, how many posts do you want to scrape?\"))\n",
    "\n",
    "scraping = True\n",
    "while scraping:\n",
    "    driver = linkedIn_scraper.scraper_log_in()\n",
    "    linkedIn_scraper.search_and_scrape(search_input,search_quantity,driver)\n",
    "    linkedIn_scraper.scraper_log_out(driver)\n",
    "    scraping = False\n",
    "search_input_list = [search_input]\n",
    "c_m.json_organizer(search_input_list,search_input)\n",
    "cleaned_posts_list = c_m.CSV_duplicate_finder(search_input_list,f'{search_input}_cleaned')\n",
    "c_m.emoji_organizer(cleaned_posts_list,search_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraper used for project ##\n",
    "\n",
    "c_m.create_folders()\n",
    "\n",
    "scraping = True\n",
    "while scraping:\n",
    "    driver = linkedIn_scraper.scraper_log_in()\n",
    "    for search in c_l.search_list:\n",
    "        linkedIn_scraper.search_and_scrape(search,100,driver)\n",
    "        print(f'{search} complete!')\n",
    "    scraping = False\n",
    "linkedIn_scraper.scraper_log_out(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting JSONs to CSVs, cause i like them more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_m.json_organizer(c_l.resume_json,'resume tips.csv')\n",
    "c_m.json_organizer(c_l.interview_tips_json,'interview tips.csv')\n",
    "c_m.json_organizer(c_l.data_analysis_tips_json,'data analysis tips.csv')\n",
    "c_m.json_organizer(c_l.job_tips_json,'job tips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If wanting to run the duplicate finder one individual file, you can use this method ##\n",
    "c_m.CSV_duplicate_finder(['resume tips'],'cleaned_resume_tips')\n",
    "c_m.CSV_duplicate_finder(['interview tips'],'cleaned_interview_tips')\n",
    "c_m.CSV_duplicate_finder(['data analysis tips'],'cleaned_data_analysis_tips')\n",
    "c_m.CSV_duplicate_finder(['job tips'],'cleaned_job_tips')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_Posts has 1506 duplicates of 2436 posts\n",
      "ALL_EMOJI_LIST.csv has been created\n"
     ]
    }
   ],
   "source": [
    "## We want to pull the emojis from all NON DUPLICATED posts ##\n",
    "\n",
    "post_list = c_m.CSV_duplicate_finder(c_l.csv_list,'All_Posts')\n",
    "c_m.emoji_organizer(post_list,\"ALL_EMOJI_LIST\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
